{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e470a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "go_direct = gp.read_gmt(\"/PATH/2024-09-08/hsa_ALL_BP_direct.gmt\")\n",
    "go_prop = gp.read_gmt(\"/PATH/hsa_ALL_BP_propagated.gmt\")\n",
    "\n",
    "file_path = \"/PATH/goslim_agr.tsv\"\n",
    "\n",
    "go_slim = pd.read_csv(file_path, sep='\\t')\n",
    "go_slim[\"GO_ID\"] = go_slim[\"?x\"].astype(str).str.extract(r'(GO_\\d+)')\n",
    "go_slim[\"GO_ID\"] = go_slim[\"GO_ID\"].str.replace('_', ':')\n",
    "\n",
    "slim_set = set(go_slim['GO_ID'].tolist()) & set(go_prop.keys())\n",
    "\n",
    "go_direct_10 = [go for go, gene_list in go_direct.items() if len(gene_list) >= 20]\n",
    "go_prop_20 = [go for go, gene_list in go_prop.items() if len(gene_list) >= 20]\n",
    "\n",
    "go_use = list(set(go_direct_10).intersection(go_prop_20))\n",
    "\n",
    "graph = obonet.read_obo(\"/PATH/go.obo\")\n",
    "\n",
    "slim_ancestors = {}\n",
    "\n",
    "for slim in slim_set:\n",
    "    if slim not in graph:\n",
    "        print(slim)\n",
    "        continue\n",
    "    ancestors = nx.ancestors(graph, slim) \n",
    "    \n",
    "    slim_ancestors[slim] = ancestors\n",
    "\n",
    "go_to_slim = {}\n",
    "\n",
    "for term in go_use:\n",
    "    matching_keys = [key for key, values in slim_ancestors.items() if term in values]\n",
    "    go_to_slim[term] = matching_keys\n",
    "\n",
    "go_to_slim\n",
    "\n",
    "filtered_go_to_slim = {term: matches for term, matches in go_to_slim.items() if matches}\n",
    "filt_slim_to_go = defaultdict(list)\n",
    "\n",
    "for term, matches in filtered_go_to_slim.items():\n",
    "    for match in matches:\n",
    "        filt_slim_to_go[match].append(term)\n",
    "\n",
    "go_use = []  \n",
    "filtered_filt_slim_to_go = {}  \n",
    "\n",
    "for match, terms in filt_slim_to_go.items():\n",
    "    available_terms = [term for term in terms if term not in go_use]\n",
    "    \n",
    "    selected_terms = available_terms[:3]\n",
    "    go_use.extend(selected_terms)\n",
    "    \n",
    "    filtered_filt_slim_to_go[match] = selected_terms\n",
    "\n",
    "go_prop_use = {term: genes for term, genes in go_prop.items() if term in go_use}\n",
    "go_slim_use = {term: genes for term, genes in go_prop.items() if term in slim_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b070ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "holdout_dict = {}\n",
    "cv_fold1_dict = {}\n",
    "cv_fold2_dict = {}\n",
    "cv_fold3_dict = {}\n",
    "\n",
    "for go_term in list(go_prop_use):\n",
    "    pos_genes = set(go_prop_use[go_term])\n",
    "    pos_count = len(pos_genes)\n",
    "\n",
    "    # Get non-negative set (from the propagated slim)\n",
    "    non_neg_list = []\n",
    "    for slim in go_to_slim[go_term]:\n",
    "        non_neg_list.extend(go_slim_use[slim])\n",
    "    non_neg_list = set(non_neg_list)\n",
    "\n",
    "    all_values = [value for values in go_slim_use.values() for value in values]\n",
    "    all_values = set(all_values)\n",
    "\n",
    "    # Negative genes (candidate pool)\n",
    "    neg_genes = all_values - pos_genes - non_neg_list\n",
    "\n",
    "    # Number of negatives we want to sample\n",
    "    neg_needed = 10 * pos_count\n",
    "\n",
    "    # Identify associated and other slim terms\n",
    "    associated_slims = set(go_to_slim[go_term])\n",
    "    all_slim_terms = set(go_slim_use.keys())\n",
    "    other_slims = all_slim_terms - associated_slims\n",
    "\n",
    "    chosen_negatives = set()\n",
    "\n",
    "    if len(other_slims) > 0:\n",
    "        neg_per_slim = neg_needed // len(other_slims)\n",
    "\n",
    "        for slim_term in other_slims:\n",
    "            candidate_genes = list(neg_genes.intersection(go_slim_use[slim_term]))\n",
    "            alloc_count = min(neg_per_slim, len(candidate_genes))\n",
    "            chosen = random.sample(candidate_genes, alloc_count) if alloc_count > 0 else []\n",
    "            chosen_negatives.update(chosen)\n",
    "\n",
    "        allocated_count = len(chosen_negatives)\n",
    "        if allocated_count < neg_needed:\n",
    "            remainder = neg_needed - allocated_count\n",
    "            remaining_candidates = list(neg_genes - chosen_negatives)\n",
    "            if remainder > len(remaining_candidates):\n",
    "                remainder = len(remaining_candidates)\n",
    "            if remainder > 0:\n",
    "                chosen_negatives.update(random.sample(remaining_candidates, remainder))\n",
    "    else:\n",
    "        chosen_negatives = set(random.sample(neg_genes, min(neg_needed, len(neg_genes))))\n",
    "    \n",
    "    pos_list = list(pos_genes)\n",
    "    neg_list = list(chosen_negatives)\n",
    "    random.shuffle(pos_list)\n",
    "    random.shuffle(neg_list)\n",
    "    \n",
    "    holdout_pos_count = max(1, int(0.2 * len(pos_list))) if len(pos_list) > 0 else 0\n",
    "    holdout_neg_count = max(1, int(0.2 * len(neg_list))) if len(neg_list) > 0 else 0\n",
    "    \n",
    "    holdout_pos = pos_list[:holdout_pos_count]\n",
    "    holdout_neg = neg_list[:holdout_neg_count]\n",
    "    \n",
    "    train_pos = pos_list[holdout_pos_count:]\n",
    "    train_neg = neg_list[holdout_neg_count:]\n",
    "    \n",
    "    def split_into_folds(items, n_folds=3):\n",
    "        fold_size = len(items) // n_folds\n",
    "        folds = []\n",
    "        start = 0\n",
    "        for i in range(n_folds):\n",
    "            extra = 1 if i < (len(items) % n_folds) else 0\n",
    "            end = start + fold_size + extra\n",
    "            folds.append(items[start:end])\n",
    "            start = end\n",
    "        return folds\n",
    "    \n",
    "    pos_folds = split_into_folds(train_pos, 3)\n",
    "    neg_folds = split_into_folds(train_neg, 3)\n",
    "        \n",
    "    holdout_data = [{\"gene\": g, \"result\": 1} for g in holdout_pos] + \\\n",
    "                   [{\"gene\": g, \"result\": 0} for g in holdout_neg]\n",
    "    holdout_df = pd.DataFrame(holdout_data)\n",
    "    \n",
    "    fold_dfs = []\n",
    "    for i in range(3):\n",
    "        fold_data = [{\"gene\": g, \"result\": 1} for g in pos_folds[i]] + \\\n",
    "                    [{\"gene\": g, \"result\": 0} for g in neg_folds[i]]\n",
    "        fold_df = pd.DataFrame(fold_data)\n",
    "        fold_dfs.append(fold_df)\n",
    "    \n",
    "    holdout_dict[go_term] = holdout_df\n",
    "    cv_fold1_dict[go_term] = fold_dfs[0]\n",
    "    cv_fold2_dict[go_term] = fold_dfs[1]\n",
    "    cv_fold3_dict[go_term] = fold_dfs[2]\n",
    "\n",
    "for go_term in holdout_dict.keys():\n",
    "    holdout_pos = (holdout_dict[go_term]['result'] == 1).sum()\n",
    "    holdout_neg = (holdout_dict[go_term]['result'] == 0).sum()\n",
    "    \n",
    "    fold1_pos = (cv_fold1_dict[go_term]['result'] == 1).sum()\n",
    "    fold1_neg = (cv_fold1_dict[go_term]['result'] == 0).sum()\n",
    "    \n",
    "    fold2_pos = (cv_fold2_dict[go_term]['result'] == 1).sum()\n",
    "    fold2_neg = (cv_fold2_dict[go_term]['result'] == 0).sum()\n",
    "    \n",
    "    fold3_pos = (cv_fold3_dict[go_term]['result'] == 1).sum()\n",
    "    fold3_neg = (cv_fold3_dict[go_term]['result'] == 0).sum()\n",
    "    \n",
    "    print(\n",
    "        f\"{go_term}: \"\n",
    "        f\"Holdout(Pos={holdout_pos}, Neg={holdout_neg}) | \"\n",
    "        f\"Fold1(Pos={fold1_pos}, Neg={fold1_neg}) | \"\n",
    "        f\"Fold2(Pos={fold2_pos}, Neg={fold2_neg}) | \"\n",
    "        f\"Fold3(Pos={fold3_pos}, Neg={fold3_neg})\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4340dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [\"go_cv_fold1_dict_all.pkl\", \"go_cv_fold2_dict_all.pkl\", \"go_cv_fold3_dict_all.pkl\", \"go_holdout_dict_all.pkl\"]\n",
    "data_dicts = [cv_fold1_dict, cv_fold2_dict, cv_fold3_dict, holdout_dict]\n",
    "\n",
    "for file_name, data_dict in zip(file_names, data_dicts):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(data_dict, f)\n",
    "\n",
    "file_names"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
